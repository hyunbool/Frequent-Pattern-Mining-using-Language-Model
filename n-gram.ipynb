{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-gram 언어모델\n",
    "단어 문장 대신 아이템 넣어서 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "#코드 참조:\n",
    "#데이터 사이언스 스쿨: 확률론적 언어 모형(https://datascienceschool.net/view-notebook/a0c848e1e2d343d685e6077c35c4203b/)\n",
    "from nltk import bigrams, word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "nltk.download(\"book\", quiet=True)\n",
    "from nltk.book import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-25m/movies.csv')\n",
    "ratings = pd.read_csv('ml-25m/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['liked'] = np.where(ratings['rating']>=4, 1, 0)\n",
    "ratings['movieId'] = ratings['movieId'].astype('str')\n",
    "gp_user_like = ratings.groupby(['liked', 'userId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 n이 좋아한 영화 => positive example\n",
    "# 유저 n이 싫어하는 영화 별로 그룹, 좋아하는 영화 별로 그룹핑\n",
    "splitted_movies = [gp_user_like.get_group(gp)['movieId'].tolist() for gp in gp_user_like.groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-15737e111b02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmovie_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplitted_movies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "for movie_list in splitted_movies:\n",
    "    random.shuffle(movie_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(splitted_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아이템셋 토큰화\n",
    "- window 사이즈 2인 n-gram 모형\n",
    "- SS: 문장의 처음\n",
    "- SE: 문장의 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for tokens in splitted_movies:\n",
    "    bigram = ngrams(tokens, 2, pad_left=True, pad_right=True, left_pad_symbol=\"SS\", right_pad_symbol=\"SE\")\n",
    "    sentences += [t for t in bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SS', '306'), ('306', '899'), ('899', '1175'), ('1175', '1217'), ('1217', '1260'), ('1260', '2011'), ('2011', '2012'), ('2012', '2068'), ('2068', '2161'), ('2161', '4308'), ('4308', '4422'), ('4422', '5269'), ('5269', '5684'), ('5684', '5912'), ('5912', '6539'), ('6539', '6954'), ('6954', '7318'), ('7318', '7323'), ('7323', '7327'), ('7327', '7820'), ('7820', '7937'), ('7937', '7938'), ('7938', '7939'), ('7939', '8014'), ('8014', '8405'), ('8405', '8685'), ('8685', '8729'), ('8729', '8873'), ('8873', '27193'), ('27193', '27721'), ('27721', '31956'), ('31956', 'SE'), ('SS', '1'), ('1', '62'), ('62', '261'), ('261', '266'), ('266', '380'), ('380', '480'), ('480', '524'), ('524', '553'), ('553', '588'), ('588', '653'), ('653', '858'), ('858', '1035'), ('1035', '1080'), ('1080', '1201'), ('1201', '1271'), ('1271', '1299'), ('1299', '1302'), ('1302', '1431'), ('1431', '1465'), ('1465', '1485'), ('1485', '1527'), ('1527', '1587'), ('1587', '1722'), ('1722', '1923'), ('1923', '1957'), ('1957', '1968'), ('1968', '2081'), ('2081', '2115'), ('2115', '2273'), ('2273', '2324'), ('2324', '2406'), ('2406', '2643'), ('2643', '2720'), ('2720', '2761'), ('2761', '2797'), ('2797', '2987'), ('2987', '3098'), ('3098', '3107'), ('3107', '3148'), ('3148', '3175'), ('3175', '3479'), ('3479', '3889'), ('3889', '3916'), ('3916', '3948'), ('3948', '3994'), ('3994', '4019'), ('4019', '4023'), ('4023', '4535'), ('4535', '4571'), ('4571', '4857'), ('4857', '5010'), ('5010', '5445'), ('5445', '5574'), ('5574', '6156'), ('6156', '6157'), ('6157', '6213'), ('6213', '6287'), ('6287', '6565'), ('6565', '6753'), ('6753', '7004'), ('7004', '7007'), ('7007', '7090'), ('7090', '7162'), ('7162', '7624'), ('7624', '8958'), ('8958', '30848'), ('30848', '31923'), ('31923', '33166'), ('33166', '34162'), ('34162', '35836'), ('35836', '36527'), ('36527', 'SE'), ('SS', '173'), ('173', '442'), ('442', '480'), ('480', '780'), ('780', '1127'), ('1127', '1198'), ('1198', '1270'), ('1270', '1320'), ('1320', '1676'), ('1676', '1882'), ('1882', '2105'), ('2105', '2641'), ('2641', '3285'), ('3285', '3328'), ('3328', '3408'), ('3408', '3452'), ('3452', '3484'), ('3484', '3534'), ('3534', '3646'), ('3646', '3745'), ('3745', '3753'), ('3753', '3755'), ('3755', '3785'), ('3785', '3798'), ('3798', '3825'), ('3825', '3827'), ('3827', '3863'), ('3863', '3879'), ('3879', '3948'), ('3948', '3968'), ('3968', '3977'), ('3977', '3979'), ('3979', '3986'), ('3986', '3988'), ('3988', '3991'), ('3991', '3999'), ('3999', '4018'), ('4018', '4025'), ('4025', '4069'), ('4069', '4148'), ('4148', '4167'), ('4167', '4232'), ('4232', '4234'), ('4234', '4246'), ('4246', '4308'), ('4308', '4340')]\n"
     ]
    }
   ],
   "source": [
    "print(sentences[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieId_to_name = pd.Series(movies.title.values, index = movies.movieId.values).to_dict()\n",
    "name_to_movieId = pd.Series(movies.movieId.values, index = movies.title).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = ConditionalFreqDist(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
    "cpd = ConditionalProbDist(cfd, MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MLEProbDist based on 0 samples>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_score(s):\n",
    "    p = 0.0\n",
    "    for i in range(len(s) - 1):\n",
    "        c = s[i]\n",
    "        w = s[i + 1]\n",
    "        p += np.log(cpd[c].prob(w) + np.finfo(float).eps)\n",
    "    return np.exp(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(seed=None, start_word=\"SS\"):\n",
    "    if seed is not None:\n",
    "        import random\n",
    "        random.seed(seed)\n",
    "        \n",
    "    c = start_word\n",
    "    sentence = []\n",
    "    sentence.append(c)\n",
    "    \n",
    "    while True:\n",
    "        if c not in cpd:\n",
    "            break\n",
    "        w = cpd[c].generate()\n",
    "        if w == \"SE\":\n",
    "            break\n",
    "        else:\n",
    "            w2 = w\n",
    "        sentence.append(w2)\n",
    "        c = w\n",
    "    \n",
    "    moviename = []\n",
    "    for i in sentence:\n",
    "        mname = movieId_to_name[int(i)]\n",
    "        moviename.append(mname)\n",
    "    \n",
    "    return sentence, moviename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence, movie = generate_sentence(start_word=\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', '3120', '8958', '7143', '106782', '4816', '6936', '2791', '1032', '160', '435', '2194', '3623', '89745', '1198', '1', '2716', '4814', '1641', '2407', '7781', '4735', '5384', '30749', '4848', '58103', '3986', '6874', '500', '1097', '50', '173343', '553', '231', '2716', '32587', '6863', '40815', '7669', '2427', '3006', '296', '3538', '5225', '63082', '6874', '3996', '2011', '1247', '1721', '3176', '4776', '1391', '7206', '4966', '1587', '8798', '1266', '1250', '529', '1302', '1394', '1240', '714']\n",
      "['Grumpier Old Men (1995)', 'Distinguished Gentleman, The (1992)', 'Ray (2004)', 'Last Samurai, The (2003)', 'Wolf of Wall Street, The (2013)', 'Zoolander (2001)', 'Elf (2003)', 'Airplane! (1980)', 'Alice in Wonderland (1951)', 'Congo (1995)', 'Coneheads (1993)', 'Untouchables, The (1987)', 'Mission: Impossible II (2000)', 'Avengers, The (2012)', 'Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981)', 'Toy Story (1995)', 'Ghostbusters (a.k.a. Ghost Busters) (1984)', \"Don't Say a Word (2001)\", 'Full Monty, The (1997)', 'Cocoon (1985)', 'Twister (1990)', 'Ghosts of Mars (2001)', 'I Want to Live! (1958)', 'Hotel Rwanda (2004)', 'Mulholland Drive (2001)', 'Vantage Point (2008)', '6th Day, The (2000)', 'Kill Bill: Vol. 1 (2003)', 'Mrs. Doubtfire (1993)', 'E.T. the Extra-Terrestrial (1982)', 'Usual Suspects, The (1995)', 'Abigél (1978)', 'Tombstone (1993)', 'Dumb & Dumber (Dumb and Dumber) (1994)', 'Ghostbusters (a.k.a. Ghost Busters) (1984)', 'Sin City (2005)', 'School of Rock (2003)', 'Harry Potter and the Goblet of Fire (2005)', 'Pride and Prejudice (1995)', 'Thin Red Line, The (1998)', 'Insider, The (1999)', 'Pulp Fiction (1994)', 'East is East (1999)', 'And Your Mother Too (Y tu mamá también) (2001)', 'Slumdog Millionaire (2008)', 'Kill Bill: Vol. 1 (2003)', 'Crouching Tiger, Hidden Dragon (Wo hu cang long) (2000)', 'Back to the Future Part II (1989)', 'Graduate, The (1967)', 'Titanic (1997)', 'Talented Mr. Ripley, The (1999)', 'Training Day (2001)', 'Mars Attacks! (1996)', 'Mon Oncle (My Uncle) (1958)', 'Incredible Shrinking Man, The (1957)', 'Conan the Barbarian (1982)', 'Collateral (2004)', 'Unforgiven (1992)', 'Bridge on the River Kwai, The (1957)', 'Searching for Bobby Fischer (1993)', 'Field of Dreams (1989)', 'Raising Arizona (1987)', 'Terminator, The (1984)', 'Dead Man (1995)']\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개선해야할 점\n",
    "- 조건부 확률... 순서는 상관이 없기 때문에 이 점 개선\n",
    "- 출발 아이템을 frequent한 것으로 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_usr_with_id(mid):\n",
    "    usr = []\n",
    "    for i in splitted_movies:\n",
    "        if mid in i:\n",
    "            usr.append(i)\n",
    "    \n",
    "    # 해당 mid를 본 유저와 생성한 sentence를 비교\n",
    "    compare = [] # 생성한 sentence와 비교해 일치율 구하기\n",
    "    for u in usr:\n",
    "        c = list(set(u).intersection(sentence))\n",
    "        prob = (len(c) / len(sentence)) * 100\n",
    "        compare.append(prob)\n",
    "    \n",
    "    return usr, compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "usr, compare = find_usr_with_id(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2840"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare.index(max(compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4776"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# support 실제 얼마나 나오는지\n",
    "# 출발도 frequent한 아이템을 가지고 real support 구하기\n",
    "# association rule로 구하는 것 보다 이게 리즈너블 한가?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
